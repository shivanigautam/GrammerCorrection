{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2672778,"sourceType":"datasetVersion","datasetId":1626196}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece\n\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\nfrom tqdm.auto import tqdm\n\n\n# Replace 'your_dataset.csv' with the path to your dataset\ndf = pd.read_csv('/kaggle/input/grammaratical-error-correction-dataset/train_updated.csv')\n# df.to_csv('train_updated.csv')\ndf['input'] = \"correct grammar: \" + df['input']\nclass GrammarCorrectionDataset(Dataset):\n    def __init__(self, tokenizer, data, max_length=256):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        input_text = self.data.iloc[idx]['input']\n        target_text = self.data.iloc[idx]['target']\n\n        input_encoding = self.tokenizer(input_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n        target_encoding = self.tokenizer(target_text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n\n        return {\n            'input_ids': input_encoding.input_ids.squeeze(),\n            'attention_mask': input_encoding.attention_mask.squeeze(),\n            'labels': target_encoding.input_ids.squeeze(),\n        }\n\ntokenizer = T5Tokenizer.from_pretrained('t5-base')\ndataset = GrammarCorrectionDataset(tokenizer, df)\nloader = DataLoader(dataset, batch_size=8, shuffle=True)\n\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.train()\n\n\noptimizer = AdamW(model.parameters(), lr=5e-5)\nnum_epochs = 8\n\nfor epoch in range(num_epochs):\n    loop = tqdm(loader, leave=True)\n    for batch in loop:\n        optimizer.zero_grad()\n\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        loop.set_description(f'Epoch {epoch+1}')\n        loop.set_postfix(loss=loss.item())\n\n# Prediction Example\n\n# Save the model and the tokenizer\nmodel_save_path = '/kaggle/working/model.pt'\ntokenizer_save_path = '/kaggle/working/tokenizer'\n\n# Saving the model's state_dict\ntorch.save(model.state_dict(), model_save_path)\n\n# Saving the tokenizer\ntokenizer.save_pretrained(tokenizer_save_path)\n# Load the tokenizer\ntokenizer = T5Tokenizer.from_pretrained(tokenizer_save_path)\n\n# Initialize the model\nmodel = T5ForConditionalGeneration.from_pretrained('t5-base')\n\n# Load the model's state_dict\nmodel.load_state_dict(torch.load(model_save_path))\nmodel.to(device)\n\n\n\nmodel.eval()\ninput_text = \"correct grammar: I want to talk about nocive or bad products like alcohol , hair spray and cigarrets .\"\ninput_encoding = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n\nwith torch.no_grad():\n    output_sequences = model.generate(\n        input_ids=input_encoding,\n        max_length=40,\n        temperature=1.0,\n        top_k=50,\n        top_p=0.95,\n        repetition_penalty=1.0,\n        do_sample=True,\n        num_return_sequences=1\n    )\n\ncorrected_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\nprint(\"Corrected Text:\", corrected_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-09T12:06:49.478419Z","iopub.execute_input":"2024-03-09T12:06:49.479498Z","iopub.status.idle":"2024-03-09T12:07:16.109474Z","shell.execute_reply.started":"2024-03-09T12:06:49.479460Z","shell.execute_reply":"2024-03-09T12:07:16.107875Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect grammar: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# df['target'] = df['Standard English']\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m y\u001b[38;5;241m=\u001b[39m\u001b[43muu\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGrammarCorrectionDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenizer, data, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m):\n","\u001b[0;31mNameError\u001b[0m: name 'uu' is not defined"],"ename":"NameError","evalue":"name 'uu' is not defined","output_type":"error"}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-03-09T09:46:17.043772Z","iopub.execute_input":"2024-03-09T09:46:17.044109Z","iopub.status.idle":"2024-03-09T09:46:17.088135Z","shell.execute_reply.started":"2024-03-09T09:46:17.044079Z","shell.execute_reply":"2024-03-09T09:46:17.087243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}